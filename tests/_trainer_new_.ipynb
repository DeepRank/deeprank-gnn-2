{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbodor/miniconda3/envs/deeprank/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import unittest\n",
    "import pytest\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "from deeprankcore.trainer import Trainer\n",
    "from deeprankcore.dataset import HDF5DataSet\n",
    "from deeprankcore.ginet import GINet\n",
    "from deeprankcore.foutnet import FoutNet\n",
    "from deeprankcore.naive_gnn import NaiveNetwork\n",
    "from deeprankcore.sGAT import sGAT\n",
    "from deeprankcore.models.metrics import (\n",
    "    OutputExporter,\n",
    "    TensorboardBinaryClassificationExporter,\n",
    "    ScatterPlotExporter\n",
    ")\n",
    "from deeprankcore.domain.features import groups, edgefeats\n",
    "from deeprankcore.domain.features import nodefeats as Nfeat\n",
    "from deeprankcore.domain import targettypes as targets\n",
    "from deeprankcore.loadonegraph import load_one_graph\n",
    "\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "default_node_features = [Nfeat.RESTYPE, Nfeat.POLARITY, Nfeat.BSA, Nfeat.RESDEPTH, Nfeat.HSE, Nfeat.INFOCONTENT, Nfeat.PSSM]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 294.67it/s, mol=1ATN_ppi.hdf5]\n",
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 405.17it/s, mol=1ATN_ppi.hdf5]\n",
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 398.51it/s, mol=1ATN_ppi.hdf5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (17554x5 and 1x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 60\u001b[0m\n\u001b[1;32m     50\u001b[0m     trainer\u001b[39m.\u001b[39msave_model(\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m     Trainer(\n\u001b[1;32m     53\u001b[0m         dataset_train,\n\u001b[1;32m     54\u001b[0m         dataset_val,\n\u001b[1;32m     55\u001b[0m         dataset_test,\n\u001b[1;32m     56\u001b[0m         model_class,\n\u001b[1;32m     57\u001b[0m         pretrained_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m _model_base_test(\n\u001b[1;32m     61\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     64\u001b[0m     GINet,\n\u001b[1;32m     65\u001b[0m     default_node_features,\n\u001b[1;32m     66\u001b[0m     [edgefeats\u001b[39m.\u001b[39;49mDISTANCE],\n\u001b[1;32m     67\u001b[0m     targets\u001b[39m.\u001b[39;49mREGRESS,\n\u001b[1;32m     68\u001b[0m     targets\u001b[39m.\u001b[39;49mIRMSD,\n\u001b[1;32m     69\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     70\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmcl\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m )\n",
      "Cell \u001b[0;32mIn [2], line 48\u001b[0m, in \u001b[0;36m_model_base_test\u001b[0;34m(train_hdf5_path, val_hdf5_path, test_hdf5_path, model_class, node_features, edge_features, task, target, transform_sigmoid, clustering_method, use_cuda)\u001b[0m\n\u001b[1;32m     33\u001b[0m     dataset_test \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     35\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     36\u001b[0m     model_class,\n\u001b[1;32m     37\u001b[0m     dataset_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     transform_sigmoid\u001b[39m=\u001b[39mtransform_sigmoid,\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(nepoch\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     50\u001b[0m trainer\u001b[39m.\u001b[39msave_model(\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m Trainer(\n\u001b[1;32m     53\u001b[0m     dataset_train,\n\u001b[1;32m     54\u001b[0m     dataset_val,\n\u001b[1;32m     55\u001b[0m     dataset_test,\n\u001b[1;32m     56\u001b[0m     model_class,\n\u001b[1;32m     57\u001b[0m     pretrained_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/trainer.py:494\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, nepoch, validate, save_model, model_path)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnepoch \u001b[39m=\u001b[39m nepoch\n\u001b[1;32m    493\u001b[0m _log\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mEpoch 0:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 494\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loader, \u001b[39m0\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m validate:\n\u001b[1;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_loader \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/trainer.py:607\u001b[0m, in \u001b[0;36mTrainer._eval\u001b[0;34m(self, loader, epoch_number, pass_name)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39mfor\u001b[39;00m _, data_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[1;32m    606\u001b[0m     data_batch \u001b[39m=\u001b[39m data_batch\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 607\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data_batch)\n\u001b[1;32m    608\u001b[0m     pred, data_batch\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_output(pred, data_batch\u001b[39m.\u001b[39my)\n\u001b[1;32m    610\u001b[0m     \u001b[39m# Check if a target value was provided (i.e. benchmarck scenario)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/ginet.py:90\u001b[0m, in \u001b[0;36mGINet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     86\u001b[0m data_ext \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mclone()\n\u001b[1;32m     88\u001b[0m \u001b[39m# EXTERNAL INTERACTION GRAPH\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# first conv block\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m data\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m act(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index, data\u001b[39m.\u001b[39;49medge_attr))\n\u001b[1;32m     91\u001b[0m cluster \u001b[39m=\u001b[39m get_preloaded_cluster(data\u001b[39m.\u001b[39mcluster0, data\u001b[39m.\u001b[39mbatch)\n\u001b[1;32m     92\u001b[0m data \u001b[39m=\u001b[39m community_pooling(cluster, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/ginet.py:49\u001b[0m, in \u001b[0;36mGINetConvLayer.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     46\u001b[0m xcol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x[col])\n\u001b[1;32m     47\u001b[0m xrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x[row])\n\u001b[0;32m---> 49\u001b[0m ed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_edge_attr(edge_attr)\n\u001b[1;32m     50\u001b[0m \u001b[39m# create edge feature by concatenating node feature\u001b[39;00m\n\u001b[1;32m     51\u001b[0m alpha \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([xrow, xcol, ed], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (17554x5 and 1x1)"
     ]
    }
   ],
   "source": [
    "# new\n",
    "\n",
    "def _model_base_test( # pylint: disable=too-many-arguments, too-many-locals\n",
    "    train_hdf5_path,\n",
    "    val_hdf5_path,\n",
    "    test_hdf5_path,\n",
    "    model_class,\n",
    "    node_features,\n",
    "    edge_features,\n",
    "    task,\n",
    "    target,\n",
    "    transform_sigmoid,\n",
    "    clustering_method,\n",
    "    use_cuda = False\n",
    "):\n",
    "\n",
    "    dataset_train = HDF5DataSet(\n",
    "        train_hdf5_path,\n",
    "        clustering_method=clustering_method)\n",
    "\n",
    "    if val_hdf5_path is not None:\n",
    "        dataset_val = HDF5DataSet(\n",
    "            val_hdf5_path,\n",
    "            clustering_method=clustering_method)\n",
    "    else:\n",
    "        dataset_val = None\n",
    "\n",
    "    if test_hdf5_path is not None:\n",
    "        dataset_test = HDF5DataSet(\n",
    "            test_hdf5_path,\n",
    "            clustering_method=clustering_method)\n",
    "    else:\n",
    "        dataset_test = None\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_class,\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        dataset_test,\n",
    "        node_features=node_features,\n",
    "        edge_features=edge_features,\n",
    "        target=target,\n",
    "        task=task,\n",
    "        batch_size=64,\n",
    "        transform_sigmoid=transform_sigmoid,\n",
    "    )\n",
    "\n",
    "    trainer.train(nepoch=10, validate=True)\n",
    "\n",
    "    trainer.save_model(\"test.pth.tar\")\n",
    "\n",
    "    Trainer(\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        dataset_test,\n",
    "        model_class,\n",
    "        pretrained_model=\"test.pth.tar\")\n",
    "\n",
    "\n",
    "_model_base_test(\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    GINet,\n",
    "    default_node_features,\n",
    "    [edgefeats.DISTANCE],\n",
    "    targets.REGRESS,\n",
    "    targets.IRMSD,\n",
    "    True,\n",
    "    \"mcl\",\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = ([1,2],[3,4])\n",
    "A = np.array(A)\n",
    "\n",
    "print(A.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deeprank')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "276ef95c56205118bc396c7ecff9f4bbaf55abeabfc798eaf375738c8dd159eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
