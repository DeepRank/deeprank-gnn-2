{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import unittest\n",
    "import pytest\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "from deeprankcore.Trainer import Trainer\n",
    "from deeprankcore.DataSet import HDF5DataSet\n",
    "\n",
    "from deeprankcore.ginet import GINet\n",
    "from deeprankcore.foutnet import FoutNet\n",
    "from deeprankcore.naive_gnn import NaiveNetwork\n",
    "from deeprankcore.sGAT import sGAT\n",
    "from deeprankcore.models.metrics import (\n",
    "    OutputExporter,\n",
    "    TensorboardBinaryClassificationExporter,\n",
    "    ScatterPlotExporter\n",
    ")\n",
    "from deeprankcore.domain.features import groups, edgefeats\n",
    "from deeprankcore.domain.features import nodefeats as Nfeat\n",
    "from deeprankcore.domain import targettypes as targets\n",
    "\n",
    "default_features = [Nfeat.RESTYPE, Nfeat.POLARITY, Nfeat.BSA, Nfeat.RESDEPTH, Nfeat.HSE, Nfeat.INFOCONTENT, Nfeat.PSSM]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "\n",
    "def _model_base_test( # pylint: disable=too-many-arguments, too-many-locals\n",
    "    train_hdf5_path,\n",
    "    val_hdf5_path,\n",
    "    test_hdf5_path,\n",
    "    model_class,\n",
    "    node_features,\n",
    "    edge_features,\n",
    "    task,\n",
    "    target,\n",
    "    metrics_exporters,\n",
    "    transform_sigmoid,\n",
    "    clustering_method,\n",
    "    use_cuda = False\n",
    "):\n",
    "\n",
    "    dataset_train = HDF5DataSet(\n",
    "        hdf5_path=train_hdf5_path,\n",
    "        root=\"./\",\n",
    "        node_feature=node_features,\n",
    "        edge_feature=edge_features,\n",
    "        task = task,\n",
    "        target=target,\n",
    "        clustering_method=clustering_method)\n",
    "\n",
    "    if val_hdf5_path is not None:\n",
    "        dataset_val = HDF5DataSet(\n",
    "            hdf5_path=val_hdf5_path,\n",
    "            root=\"./\",\n",
    "            node_feature=node_features,\n",
    "            edge_feature=edge_features,\n",
    "            task = task,\n",
    "            target=target,\n",
    "            clustering_method=clustering_method)\n",
    "    else:\n",
    "        dataset_val = None\n",
    "\n",
    "    if test_hdf5_path is not None:\n",
    "        dataset_test = HDF5DataSet(\n",
    "            hdf5_path=test_hdf5_path,\n",
    "            root=\"./\",\n",
    "            node_feature=node_features,\n",
    "            edge_feature=edge_features,\n",
    "            target=target,\n",
    "            task=task,\n",
    "            clustering_method=clustering_method)\n",
    "    else:\n",
    "        dataset_test = None\n",
    "\n",
    "    trainer = Trainer(\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        dataset_test,\n",
    "        model_class,\n",
    "        batch_size=64,\n",
    "        metrics_exporters=metrics_exporters,\n",
    "        transform_sigmoid=transform_sigmoid,\n",
    "    )\n",
    "\n",
    "    trainer.train(nepoch=10, validate=True)\n",
    "\n",
    "    trainer.save_model(\"test.pth.tar\")\n",
    "\n",
    "    Trainer(\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        dataset_test,\n",
    "        model_class,\n",
    "        pretrained_model=\"test.pth.tar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 287.95it/s, mol=1ATN_ppi.hdf5]\n",
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 271.81it/s, mol=1ATN_ppi.hdf5]\n",
      "   ['./data/hdf5/1ATN_ppi.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 352.73it/s, mol=1ATN_ppi.hdf5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  8.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  8.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.51it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "directory ``/home/dbodor/git/DeepRank/deeprank-core/tests/metrics`` exists but it can not be written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _model_base_test(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m./data/hdf5/1ATN_ppi.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     GINet,\n\u001b[1;32m      6\u001b[0m     default_features,\n\u001b[1;32m      7\u001b[0m     [edgefeats\u001b[39m.\u001b[39;49mDISTANCE],\n\u001b[1;32m      8\u001b[0m     targets\u001b[39m.\u001b[39;49mREGRESS,\n\u001b[1;32m      9\u001b[0m     targets\u001b[39m.\u001b[39;49mIRMSD,\n\u001b[1;32m     10\u001b[0m     [OutputExporter(\u001b[39m'\u001b[39;49m\u001b[39m/home/dbodor/git/DeepRank/deeprank-core/metrics/notebooks\u001b[39;49m\u001b[39m'\u001b[39;49m)],\n\u001b[1;32m     11\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmcl\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m )\n",
      "Cell \u001b[0;32mIn [10], line 61\u001b[0m, in \u001b[0;36m_model_base_test\u001b[0;34m(train_hdf5_path, val_hdf5_path, test_hdf5_path, model_class, node_features, edge_features, task, target, metrics_exporters, transform_sigmoid, clustering_method, use_cuda)\u001b[0m\n\u001b[1;32m     49\u001b[0m     dataset_test \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     51\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     52\u001b[0m     dataset_train,\n\u001b[1;32m     53\u001b[0m     dataset_val,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     transform_sigmoid\u001b[39m=\u001b[39mtransform_sigmoid,\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(nepoch\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     63\u001b[0m trainer\u001b[39m.\u001b[39msave_model(\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m Trainer(\n\u001b[1;32m     66\u001b[0m     dataset_train,\n\u001b[1;32m     67\u001b[0m     dataset_val,\n\u001b[1;32m     68\u001b[0m     dataset_test,\n\u001b[1;32m     69\u001b[0m     model_class,\n\u001b[1;32m     70\u001b[0m     pretrained_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.pth.tar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/Trainer.py:411\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, nepoch, validate, save_model, model_path)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_saved_model \u001b[39m=\u001b[39m epoch\n\u001b[1;32m    409\u001b[0m     _log\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLast model saved at epoch # \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_saved_model\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 411\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomplete_exporter\u001b[39m.\u001b[39;49msave_all_metrics()\n",
      "File \u001b[0;32m~/git/DeepRank/deeprank-core/deeprankcore/models/metrics.py:298\u001b[0m, in \u001b[0;36mConciseOutputExporter.save_all_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_all_metrics\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mto_hdf(\n\u001b[1;32m    299\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_directory_path, \u001b[39m'\u001b[39;49m\u001b[39mmetrics.hdf5\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    300\u001b[0m         key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmetrics\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    301\u001b[0m         mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/pandas/core/generic.py:2763\u001b[0m, in \u001b[0;36mNDFrame.to_hdf\u001b[0;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[1;32m   2759\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m pytables\n\u001b[1;32m   2761\u001b[0m \u001b[39m# Argument 3 to \"to_hdf\" has incompatible type \"NDFrame\"; expected\u001b[39;00m\n\u001b[1;32m   2762\u001b[0m \u001b[39m# \"Union[DataFrame, Series]\" [arg-type]\u001b[39;00m\n\u001b[0;32m-> 2763\u001b[0m pytables\u001b[39m.\u001b[39;49mto_hdf(\n\u001b[1;32m   2764\u001b[0m     path_or_buf,\n\u001b[1;32m   2765\u001b[0m     key,\n\u001b[1;32m   2766\u001b[0m     \u001b[39mself\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   2767\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   2768\u001b[0m     complevel\u001b[39m=\u001b[39;49mcomplevel,\n\u001b[1;32m   2769\u001b[0m     complib\u001b[39m=\u001b[39;49mcomplib,\n\u001b[1;32m   2770\u001b[0m     append\u001b[39m=\u001b[39;49mappend,\n\u001b[1;32m   2771\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m   2772\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2773\u001b[0m     min_itemsize\u001b[39m=\u001b[39;49mmin_itemsize,\n\u001b[1;32m   2774\u001b[0m     nan_rep\u001b[39m=\u001b[39;49mnan_rep,\n\u001b[1;32m   2775\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   2776\u001b[0m     data_columns\u001b[39m=\u001b[39;49mdata_columns,\n\u001b[1;32m   2777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   2778\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   2779\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/pandas/io/pytables.py:311\u001b[0m, in \u001b[0;36mto_hdf\u001b[0;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[1;32m    309\u001b[0m path_or_buf \u001b[39m=\u001b[39m stringify_path(path_or_buf)\n\u001b[1;32m    310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     \u001b[39mwith\u001b[39;00m HDFStore(\n\u001b[1;32m    312\u001b[0m         path_or_buf, mode\u001b[39m=\u001b[39;49mmode, complevel\u001b[39m=\u001b[39;49mcomplevel, complib\u001b[39m=\u001b[39;49mcomplib\n\u001b[1;32m    313\u001b[0m     ) \u001b[39mas\u001b[39;00m store:\n\u001b[1;32m    314\u001b[0m         f(store)\n\u001b[1;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/pandas/io/pytables.py:591\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fletcher32 \u001b[39m=\u001b[39m fletcher32\n\u001b[1;32m    590\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filters \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(mode\u001b[39m=\u001b[39;49mmode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/pandas/io/pytables.py:740\u001b[0m, in \u001b[0;36mHDFStore.open\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    735\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meven in read-only mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m     )\n\u001b[1;32m    738\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 740\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m tables\u001b[39m.\u001b[39;49mopen_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/tables/file.py:300\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is already opened.  Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mclose it before reopening in write mode.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[1;32m    299\u001b[0m \u001b[39m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[39mreturn\u001b[39;00m File(filename, mode, title, root_uep, filters, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/tables/file.py:750\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m params\n\u001b[1;32m    749\u001b[0m \u001b[39m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_g_new(filename, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    752\u001b[0m \u001b[39m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_new\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/tables/hdf5extension.pyx:368\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/deeprank/lib/python3.9/site-packages/tables/utils.py:161\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m``\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m.\u001b[39mparent\u001b[39m}\u001b[39;00m\u001b[39m`` is not a directory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39maccess(path\u001b[39m.\u001b[39mparent, os\u001b[39m.\u001b[39mW_OK):\n\u001b[0;32m--> 161\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdirectory ``\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m.\u001b[39mparent\u001b[39m}\u001b[39;00m\u001b[39m`` exists but it can not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwritten\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39maccess(path, os\u001b[39m.\u001b[39mF_OK):\n",
      "\u001b[0;31mOSError\u001b[0m: directory ``/home/dbodor/git/DeepRank/deeprank-core/tests/metrics`` exists but it can not be written"
     ]
    }
   ],
   "source": [
    "_model_base_test(\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    \"./data/hdf5/1ATN_ppi.hdf5\",\n",
    "    GINet,\n",
    "    default_features,\n",
    "    [edgefeats.DISTANCE],\n",
    "    targets.REGRESS,\n",
    "    targets.IRMSD,\n",
    "    [OutputExporter('/home/dbodor/git/DeepRank/deeprank-core/metrics/notebooks')],\n",
    "    True,\n",
    "    \"mcl\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deeprank')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "276ef95c56205118bc396c7ecff9f4bbaf55abeabfc798eaf375738c8dd159eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
